# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vMRDvItSVWOHTjln0xKDZE7sESYiHpK8
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from numpy.linalg import inv
# %matplotlib inline
from sklearn.model_selection import train_test_split, cross_validate, cross_val_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error

import warnings

def fxn():
    warnings.warn("deprecated", DeprecationWarning)

with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    fxn()

from google.colab import files
uploaded = files.upload()

"""# EDA and Cleaning"""

data = pd.read_csv('real_estate_data.csv')
data.head()

data.isnull().sum()

data['house_age'] = data['tx_year'] - data['year_built']
data = data[data['house_age'] >= 0]

features = data.columns.values.tolist()
features.remove('tx_price')

cat_features = ['property_type','exterior_walls','roof']
num_features = [val for val in features if val not in cat_features]

num_df = data[num_features]
target = data['tx_price']
fig, ax = plt.subplots(5, 5, figsize=(20,20))
fig.tight_layout(pad=3)
for var, subplot in zip(num_features, ax.flatten()): sns.scatterplot(x=var, y=target, data=num_df, ax=subplot)
fig.delaxes(ax[4][3])
fig.delaxes(ax[4][4])

plt.figure(figsize=(25,16));
sns.heatmap(data=data.corr(),vmin=-1,vmax=1,linewidths=.3,annot=True, cmap=plt.cm.Reds,square=True);

plt.figure(figsize=(25,16));
sns.heatmap(data=abs(data.corr())>.9,vmin=0,vmax=1,linewidths=.3, cmap=plt.cm.Reds,square=True);

cat_df = data[cat_features]
target = data['tx_price']
fig, ax = plt.subplots(1, 3, figsize=(20,5))
for var, subplot in zip(cat_features, ax.flatten()):
    box = sns.boxplot(x=var, y=target, data=cat_df, ax=subplot)
    box.set_xticklabels(box.get_xticklabels(), rotation=45, horizontalalignment='right')

f, ax = plt.subplots(1, 3, figsize=(15,5))
sns.countplot(x='property_type', data=data, ax=ax[0], order=data['property_type'].value_counts().index)
sns.countplot(x='exterior_walls', data=data, ax=ax[1], order=data['exterior_walls'].value_counts().index)
sns.countplot(x='roof', data=data, ax=ax[2], order=data['roof'].value_counts().index)
ax[0].set_title('Property Type')
ax[1].set_title('Material of Exterior Walls')
ax[1].tick_params(axis='x',rotation=90)
ax[2].set_title('Material of Roof')
ax[2].tick_params(axis='x',rotation=90)

ax = sns.catplot(x='property_type', hue='exterior_walls', data=data, kind='count')

plt.hist(data.tx_price, bins=10)
plt.xlabel('Transaction Price')
plt.ylabel('Frequency')
plt.show()

data.basement = data.basement.fillna(0)

data.roof.replace('composition', 'Composition', inplace=True)
data.roof.replace('asphalt', 'Asphalt', inplace=True)
data.roof.replace(['asphalt,shake-shingle', 'shake-shingle'], 'Shake Shingle', inplace=True)
data.roof = data.roof.fillna(data.roof.mode()[0])

sub_data = data['property_type'] == 'Single-Family'
data.loc[sub_data, 'exterior_walls'] = data.loc[sub_data, 'exterior_walls'].fillna('Siding (Alum/Vinyl)')

sub_data = data['property_type'] == 'Apartment / Condo / Townhouse'
data.loc[sub_data, 'exterior_walls'] = data.loc[sub_data, 'exterior_walls'].fillna('Brick')

data = data[(data['insurance'] < 1200) & (data['property_tax'] < 4000)]

"""# Feature Engineering"""

correlation_matrix = data.corr().abs()

upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape),k=1).astype(bool))
drop_columns = [column for column in upper_triangle.columns if any(upper_triangle[column] >= 0.9)]
print("Highly Correlated Features which could be removed: " ,drop_columns)

drop_columns = ['nightlife', 'cafes', 'insurance', 'year_built']
data = data.drop(drop_columns, axis=1)

num_cols = data.columns[data.dtypes.apply(lambda c: np.issubdtype(c, np.number))]
num_cols = num_cols.to_list()
num_cols.remove('tx_price')

enc = OrdinalEncoder(categories=[["Apartment / Condo / Townhouse", "Single-Family"]])
data["property_type_enc"] = enc.fit_transform(data['property_type'].to_numpy().reshape(-1,1))
data = data.drop(columns=['property_type'])

data = pd.get_dummies(data)

plt.figure(figsize=(25,16));
sns.heatmap(data=abs(data.corr())>.9,vmin=0,vmax=1,linewidths=.3,cmap=plt.cm.Reds,square=True);

X = data.drop(columns=['tx_price'])
y = np.log(data['tx_price'])

feature_names = X.columns.values.tolist()

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

ss = StandardScaler()
X_train[num_cols] = ss.fit_transform(X_train[num_cols])
X_test[num_cols] = ss.transform(X_test[num_cols])

"""# Models

Baseline Model
"""

y_pred = np.ones(y_train.shape[0]) * y_train.mean()

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(y_train, y_pred))
print("MSE on train set : ", mean_squared_error(y_train, y_pred))
print("MAE on train set : ", mean_absolute_error(y_train, y_pred))

y_pred = np.ones(y_test.shape[0]) * y_train.mean()

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred))
print("MSE on test set : ", mean_squared_error(y_test, y_pred))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred))

"""Regression Model (Lasso, Ridge, Elastic Net) (Pavan)"""

#Adding Bias
ones_train = np.ones((X_train.shape[0],1))
ones_test = np.ones((X_test.shape[0],1))
X_train_reg = np.hstack((X_train,ones_train))
X_test_reg = np.hstack((X_test,ones_test))

from sklearn.linear_model import Ridge

alphas = [0.001, 0.01, 0.1, 1, 10, 100]

print("\n========Model Training on Different Hyperparameters========\n")

cross_val_scores = []
hyper_params = []

for alpha in alphas:
    model = Ridge(alpha=alpha)
    scores = cross_val_score(model, X_train_reg, y_train, cv=5, error_score="raise")
    cross_val_scores.append(np.mean(scores))
    print("alpha:",alpha, " score:",np.mean(scores))
    hyper_params.append(alpha)
    
best_alpha = hyper_params[np.argmax(cross_val_scores)]

print("\n========Best Hyper Parameters========\n")
print("best_alpha:",best_alpha)

model = Ridge(alpha=best_alpha)
model.fit(X_train_reg, y_train)


y_pred_train = model.predict(X_train_reg)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(y_train, y_pred_train))
print("MSE on train set : ", mean_squared_error(y_train, y_pred_train))
print("MAE on train set : ", mean_absolute_error(y_train, y_pred_train))

y_pred_test = model.predict(X_test_reg)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred_test))
print("MSE on test set : ", mean_squared_error(y_test, y_pred_test))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred_test))

features_reg = feature_names+['Bias']
fig = plt.figure(figsize=(10, 5))
ax = sns.barplot(x=features_reg,y=model.coef_)
ax.tick_params(axis='x',rotation=90)

from sklearn.linear_model import Lasso

alphas = [0.001, 0.01, 0.1, 1, 10, 100]

print("\n========Model Training on Different Hyperparameters========\n")

cross_val_scores = []
hyper_params = []

for alpha in alphas:
    model = Lasso(alpha=alpha)
    scores = cross_val_score(model, X_train_reg, y_train, cv=5, error_score="raise")
    cross_val_scores.append(np.mean(scores))
    print("alpha:",alpha, " score:",np.mean(scores))
    hyper_params.append(alpha)
    
best_alpha = hyper_params[np.argmax(cross_val_scores)]

print("\n========Best Hyper Parameters========\n")
print("best_alpha:",best_alpha)

model = Lasso(alpha=best_alpha)
model.fit(X_train_reg, y_train)

y_pred_train = model.predict(X_train_reg)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(y_train, y_pred_train))
print("MSE on train set : ", mean_squared_error(y_train, y_pred_train))
print("MAE on train set : ", mean_absolute_error(y_train, y_pred_train))

y_pred_test = model.predict(X_test_reg)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred_test))
print("MSE on test set : ", mean_squared_error(y_test, y_pred_test))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred_test))

features_reg = feature_names+['Bias']
fig = plt.figure(figsize=(10, 5))
ax = sns.barplot(x=features_reg,y=model.coef_)
ax.tick_params(axis='x',rotation=90)

from sklearn.linear_model import ElasticNet

alphas = [0.001, 0.01, 0.1, 1, 10, 100]
l1_ratios = [0.1, 0.3, 0.5, 0.7, 0.9]

print("\n========Model Training on Different Hyperparameters========\n")

cross_val_scores = []
hyper_params = []

for alpha in alphas:
    for l1_ratio in l1_ratios:
        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)
        scores = cross_val_score(model, X_train_reg, y_train, cv=5, error_score="raise")
        cross_val_scores.append(np.mean(scores))
        print("alpha:",alpha, " score:",np.mean(scores))
        hyper_params.append([alpha,l1_ratio])
    
best_alpha, best_l1_ratio = hyper_params[np.argmax(cross_val_scores)]

print("\n========Best Hyper Parameters========\n")
print("best_alpha:",best_alpha, " best_l1_ratio:",best_l1_ratio)

model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)
model.fit(X_train_reg, y_train)

y_pred_train = model.predict(X_train_reg)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(y_train, y_pred_train))
print("MSE on train set : ", mean_squared_error(y_train, y_pred_train))
print("MAE on train set : ", mean_absolute_error(y_train, y_pred_train))

y_pred_test = model.predict(X_test_reg)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred_test))
print("MSE on test set : ", mean_squared_error(y_test, y_pred_test))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred_test))

features_reg = feature_names+['Bias']
fig = plt.figure(figsize=(10, 5))
ax = sns.barplot(x=features_reg,y=model.coef_)
ax.tick_params(axis='x',rotation=90)

"""Random Forest & Gradient Boosting Models (Pavan)"""

from sklearn.ensemble import RandomForestRegressor

n_estimators = [10, 25, 50]
max_features = [10, 20, 30, 'auto']
max_depths = [3, 6, 9]

print("\n========Model Training on Different Hyperparameters========\n")

cross_val_scores = []
hyper_params = []
for n_estimator in n_estimators:
    for max_depth in max_depths:
        for max_feature in max_features:
            model = RandomForestRegressor(n_estimators=n_estimator,max_depth=max_depth,max_features=max_feature)
            scores = cross_val_score(model, X_train, y_train, cv=5, error_score="raise")
            cross_val_scores.append(np.mean(scores))
            print("n_estimator:",n_estimator," max_depth:",max_depth, " max_features:",max_feature, " score:",np.mean(scores))
            hyper_params.append([n_estimator,max_depth,max_feature])
        
best_n_estimator, best_max_depth, best_max_feature = hyper_params[np.argmax(cross_val_scores)]

print("\n========Best Hyper Parameters========\n")
print("best_n_estimator:",best_n_estimator," best_max_depth:",best_max_depth," best_max_features:",best_max_feature)

model = RandomForestRegressor(n_estimators=best_n_estimator, max_depth=best_max_depth, max_features=best_max_feature)
model.fit(X_train, y_train)

y_pred_train = model.predict(X_train)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(y_train, y_pred_train))
print("MSE on train set : ", mean_squared_error(y_train, y_pred_train))
print("MAE on train set : ", mean_absolute_error(y_train, y_pred_train))

y_pred_test = model.predict(X_test)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred_test))
print("MSE on test set : ", mean_squared_error(y_test, y_pred_test))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred_test))

feat_imps = zip(feature_names, model.feature_importances_)
feats, imps = zip(*(sorted(list(filter(lambda x:x[1] != 0, feat_imps)), key=lambda x: x[1], reverse=True)))

plt.figure(figsize=(10, 5))
ax = sns.barplot(x=list(feats), y=list(imps))
ax.tick_params(axis='x', rotation=90)
plt.show()

from sklearn.ensemble import GradientBoostingRegressor

n_estimators = [10, 25, 50]
learning_rates = [0.01, 0.1, 0.2]
max_depths = [3, 6, 9]

print("\n========Model Training on Different Hyperparameters========\n")

cross_val_scores = []
hyper_params = []
for n_estimator in n_estimators:
    for max_depth in max_depths:
        for learning_rate in learning_rates:
            model = GradientBoostingRegressor(n_estimators=n_estimator,max_depth=max_depth,learning_rate=learning_rate)
            scores = cross_val_score(model, X_train, y_train, cv=5, error_score="raise")
            cross_val_scores.append(np.mean(scores))
            print("n_estimator:",n_estimator," max_depth:",max_depth, " learning_rate:",learning_rate, " score:",np.mean(scores))
            hyper_params.append([n_estimator,max_depth,learning_rate])
        
best_n_estimator, best_max_depth, best_learning_rate = hyper_params[np.argmax(cross_val_scores)]

print("\n========Best Hyper Parameters========\n")
print("best_n_estimator:",best_n_estimator," best_max_depth:",best_max_depth," best_learning_rate:",best_learning_rate)

model = GradientBoostingRegressor(n_estimators=best_n_estimator, max_depth=best_max_depth, learning_rate=best_learning_rate)
model.fit(X_train, y_train)



y_pred_train = model.predict(X_train)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(y_train, y_pred_train))
print("MSE on train set : ", mean_squared_error(y_train, y_pred_train))
print("MAE on train set : ", mean_absolute_error(y_train, y_pred_train))

y_pred_test = model.predict(X_test)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred_test))
print("MSE on test set : ", mean_squared_error(y_test, y_pred_test))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred_test))

feat_imps = zip(feature_names, model.feature_importances_)
feats, imps = zip(*(sorted(list(filter(lambda x:x[1] != 0, feat_imps)), key=lambda x: x[1], reverse=True)))

plt.figure(figsize=(10, 5))
ax = sns.barplot(x=list(feats), y=list(imps))
ax.tick_params(axis='x', rotation=90)
plt.show()

"""XGBoost (Tengteng)"""

scalerX = StandardScaler()                               # Set our standard scaler
#scalerX = MinMaxScaler()
scalerY = StandardScaler()                               # Set our standard scaler
#scalerY = MinMaxScaler()


df_X_train = scalerX.fit_transform(X_train)           # Fit and transform scalar on X_train
df_X_test = scalerX.transform(X_test)                 # Transform X_test


df_y_train = scalerX.fit_transform(y_train.values.reshape(-1,1))           # Fit and transform scalar on X_train
df_y_test = scalerX.transform(y_test.values.reshape(-1,1))                 # Transform X_test

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from xgboost import XGBRegressor

n_estimators = [100, 150]
learning_rate = np.logspace(-1,0, 2)
max_depth = [7, 15]

params = {'n_estimators': n_estimators, 'learning_rate': learning_rate, 'max_depth': max_depth}

reg = XGBRegressor()

print()
print("Here is XGBoosting Regression result:")
grid = GridSearchCV(reg, params, cv=5, return_train_score=True, n_jobs=-1)
grid.fit(df_X_train, df_y_train)

print('Corresponding parameters are, :', grid.best_params_)

xg_y_train_pred = grid.best_estimator_.predict(df_X_train)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(df_y_train, xg_y_train_pred))
print("MSE on train set : ", mean_squared_error(df_y_train, xg_y_train_pred))
print("MAE on train set : ", mean_absolute_error(df_y_train, xg_y_train_pred))


xg_y_test_pred = grid.best_estimator_.predict(df_X_test)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(df_y_test, xg_y_test_pred))
print("MSE on test set : ", mean_squared_error(df_y_test, xg_y_test_pred))
print("MAE on test set : ", mean_absolute_error(df_y_test, xg_y_test_pred))

"""LightGBM (Tengteng)"""

import lightgbm as lgb

n_estimators = [100, 150]
learning_rate = np.logspace(-1,0, 2)
max_depth = [7, 15]


params = {'n_estimators': n_estimators, 'learning_rate': learning_rate, 'max_depth': max_depth}

reg = lgb.LGBMRegressor()

print()
print("Here is LightGBM Regressor result:")
grid_lgb = GridSearchCV(reg, params, cv=5, return_train_score=True, n_jobs=-1)
grid_lgb.fit(df_X_train, df_y_train)

print()
print('Corresponding parameters are, :', grid_lgb.best_params_)

lgb_y_train_pred = grid_lgb.best_estimator_.predict(df_X_train)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(df_y_train, lgb_y_train_pred))
print("MSE on train set : ", mean_squared_error(df_y_train, lgb_y_train_pred))
print("MAE on train set : ", mean_absolute_error(df_y_train, lgb_y_train_pred))


lgb_y_test_pred = grid_lgb.best_estimator_.predict(df_X_test)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(df_y_test, lgb_y_test_pred))
print("MSE on test set : ", mean_squared_error(df_y_test, lgb_y_test_pred))
print("MAE on test set : ", mean_absolute_error(df_y_test, lgb_y_test_pred))

"""Catboost (Nitya)"""

!pip install catboost
from catboost import CatBoostRegressor
from sklearn.model_selection import RandomizedSearchCV

catr = CatBoostRegressor()

grid = {'learning_rate': [0.03, 0.1],
        'max_depth': [3, 5, 7], 
        'l2_leaf_reg': [1, 3, 5]}

print("Training Catboost...")
rand_catr = RandomizedSearchCV(catr, grid, cv=5, return_train_score=True, n_jobs=-1)
rand_catr.fit(df_X_train, df_y_train, verbose = 1)


print(f'Best Params: {rand_catr.best_params_}')

cat_y_train_pred = rand_catr.best_estimator_.predict(df_X_train)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(df_y_train, cat_y_train_pred))
print("MSE on train set : ", mean_squared_error(df_y_train, cat_y_train_pred))
print("MAE on train set : ", mean_absolute_error(df_y_train, cat_y_train_pred))

cat_y_test_pred = rand_catr.best_estimator_.predict(df_X_test)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(df_y_test, cat_y_test_pred))
print("MSE on test set : ", mean_squared_error(df_y_test, cat_y_test_pred))
print("MAE on test set : ", mean_absolute_error(df_y_test, cat_y_test_pred))

plt.figure(figsize = (15,10))
plt.barh(sorted(X_train.columns), sorted(rand_catr.best_estimator_.feature_importances_))
plt.title('Feature Importances - CatBoost')

"""Support Vector Regression (Yunze)


"""

from sklearn.svm import SVR

Cs = [1, 10, 100, 1000, 10000]
gammas = [0.001, 0.01, 0.1, 'auto']

print("\n========Model Training on Different Hyperparameters========\n")

cross_val_scores = []
hyper_params = []
for C in Cs:
    for gamma in gammas:
        model = SVR(C=C, gamma=gamma, kernel='rbf')
        scores = cross_val_score(model, X_train, y_train, cv=5, error_score="raise")
        cross_val_scores.append(np.mean(scores))
        print("penalty (C):", C, " gamma:", gamma, " score:", np.mean(scores))
        hyper_params.append([C, gamma])
        
best_C, best_gamma = hyper_params[np.argmax(cross_val_scores)]

print("\n========Best Hyper Parameters========\n")
print("best_C:", best_C, " best_gamma:", gamma)

model = SVR(C=best_C, gamma=best_gamma, kernel='rbf')
model.fit(X_train, y_train)

y_pred = model.predict(X_train)

print("\n========Evaluation on Train Set========\n")
print("R2 score on train set : ",r2_score(y_train, y_pred))
print("MSE on train set : ", mean_squared_error(y_train, y_pred))
print("MAE on train set : ", mean_absolute_error(y_train, y_pred))

y_pred = model.predict(X_test)

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred))
print("MSE on test set : ", mean_squared_error(y_test, y_pred))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred))

"""Deep Learning Model (John)"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential 
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError, MeanSquaredLogarithmicError
from sklearn.preprocessing import StandardScaler, RobustScaler
!pip install -q -U keras-tuner
import keras_tuner as kt

mae = MeanAbsoluteError()
mse = MeanSquaredError()
msle = MeanSquaredLogarithmicError()

scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

def build_model(hp):
  model_opt = Sequential()
  
  hp_units1 = hp.Int('units1', min_value=48, max_value=528, step=24)
  hp_units2 = hp.Int('units2', min_value=48, max_value=528, step=24)
  hp_units3 = hp.Int('units3', min_value=48, max_value=528, step=24)
  #hp_units4 = hp.Int('units4', min_value=48, max_value=528, step=24)
  #hp_units5 = hp.Int('units5', min_value=48, max_value=528, step=24)

  model_opt.add(Dense(units=hp_units1, activation=hp.Choice('dense_activation1', values=['relu', 'linear'])))
  model_opt.add(Dense(units=hp_units2, activation=hp.Choice('dense_activation2', values=['relu', 'linear'])))
  model_opt.add(Dense(units=hp_units3, activation=hp.Choice('dense_activation3', values=['relu', 'linear'])))
  #model_opt.add(Dense(units=hp_units4, activation=hp.Choice('dense_activation4', values=['relu', 'linear'])))
  #model_opt.add(Dense(units=hp_units5, activation=hp.Choice('dense_activation5', values=['relu', 'linear'])))
  '''
  hp_leak1 = hp.Float('alpha1', min_value=0, max_value=.1, step=.01)
  hp_leak2 = hp.Float('alpha2', min_value=0, max_value=.1, step=.01)
  hp_leak3 = hp.Float('alpha3', min_value=0, max_value=.1, step=.01)
  hp_leak4 = hp.Float('alpha4', min_value=0, max_value=.1, step=.01)
  hp_leak5 = hp.Float('alpha5', min_value=0, max_value=.1, step=.01)
  
  model_opt.add(Dense(units=hp_units1))
  model_opt.add(LeakyReLU(alpha=hp_leak1))
  model_opt.add(Dense(units=hp_units2))
  model_opt.add(LeakyReLU(alpha=hp_leak2))
  model_opt.add(Dense(units=hp_units3))
  model_opt.add(LeakyReLU(alpha=hp_leak3))
  model_opt.add(Dense(units=hp_units4))
  model_opt.add(LeakyReLU(alpha=hp_leak4))
  model_opt.add(Dense(units=hp_units5))
  model_opt.add(LeakyReLU(alpha=hp_leak5))
  '''

  #model_opt.add(Dropout(hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)))
  model_opt.add(Dense(1))

  model_opt.compile(optimizer='adam',loss='mse',metrics=['mean_squared_error'])

  return model_opt

tuner = kt.RandomSearch(build_model,objective='mean_squared_error',seed=42,max_trials=50, overwrite=True)
tuner.search(X_train_scaled, y_train, epochs=10)

for h_param in [f"units{i}" for i in range(1,4)] + [f"dense_activation{i}" for i in range(1,4)]:
  print(h_param, tuner.get_best_hyperparameters()[0].get(h_param))

  #+ [f"dense_activation{i}" for i in range(1,4)]

best_model = tuner.get_best_models(num_models=1)[0]
loss, mse = best_model.evaluate(X_test_scaled, y_test)

best_model.summary()

y_pred = best_model.predict(X_test_scaled)
y_pred_train = best_model.predict(X_train_scaled)

print("\n========Evaluation on Train Set========\n")
print("R2 score on test set : ",r2_score(y_train, y_pred_train))
print("MSE on test set : ", mean_squared_error(y_train, y_pred_train))
print("MAE on test set : ", mean_absolute_error(y_train, y_pred_train))

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred))
print("MSE on test set : ", mean_squared_error(y_test, y_pred))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred))

fig, (ax1, ax2) = plt.subplots(1, 2)
fig.set_figheight(5)
fig.set_figwidth(15)

ax1.title.set_text('True vs Predicted')
ax1.scatter(y_test,y_pred)
ax1.plot(y_test,y_test,'r')

y = np.expand_dims(y_test, axis=1)
ax2 = sns.distplot(y- y_pred)
ax2.title.set_text("Residuals")

#Baseline
model = Sequential()
model.add(Dense(48))
model.add(Dense(48))
model.add(Dense(48))
#model.add(Dense(48))
#model.add(Dense(48))
model.add(Dense(1))

#LeakyBaseline
model_lr = Sequential()
model_lr.add(Dense(48))
model_lr.add(LeakyReLU(alpha=0.05))
model_lr.add(Dense(48))
model_lr.add(LeakyReLU(alpha=0.05))
model_lr.add(Dense(48))
model_lr.add(LeakyReLU(alpha=0.05))
model_lr.add(Dense(48))
model_lr.add(LeakyReLU(alpha=0.05))
model_lr.add(Dense(48))
model_lr.add(Dense(1))

model.compile(optimizer="adam", loss='mse', metrics=['mean_squared_error'])
model_fitted = model.fit(X_train_scaled, y_train, batch_size=128, epochs=400, validation_data=(X_test_scaled, y_test), verbose = 0)
model.evaluate(X_test, y_test)

model.summary()

y_pred = model.predict(X_test_scaled)
y_pred_train = best_model.predict(X_train_scaled)

print("\n========Evaluation on Train Set========\n")
print("R2 score on test set : ",r2_score(y_train, y_pred_train))
print("MSE on test set : ", mean_squared_error(y_train, y_pred_train))
print("MAE on test set : ", mean_absolute_error(y_train, y_pred_train))

print("\n========Evaluation on Test Set========\n")
print("R2 score on test set : ",r2_score(y_test, y_pred))
print("MSE on test set : ", mean_squared_error(y_test, y_pred))
print("MAE on test set : ", mean_absolute_error(y_test, y_pred))

fig, (ax1, ax2) = plt.subplots(1, 2)
fig.set_figheight(5)
fig.set_figwidth(15)

ax1.title.set_text('True vs Predicted')
ax1.scatter(y_test,y_pred)
ax1.plot(y_test,y_test,'r')

y = np.expand_dims(y_test, axis=1)
ax2 = sns.distplot(y- y_pred)
ax2.title.set_text("Residuals")

print(model_fitted.history.keys())

fig, (ax1, ax2) = plt.subplots(1, 2)
fig.set_figheight(5)
fig.set_figwidth(15)
ax1.plot(model_fitted.history['mean_squared_error']) 
ax1.plot(model_fitted.history['val_mean_squared_error']) 
ax1.title.set_text('Model accuracy') 
ax1.set_ylabel('accuracy')
ax1.set_xlabel('epoch')
ax1.legend(['train', 'val'], loc='upper left') 

ax2.plot(model_fitted.history['loss'])
ax2.plot(model_fitted.history['val_loss'])
ax2.title.set_text('Model loss')
ax2.set_ylabel('loss')
ax2.set_xlabel('epoch')
ax2.legend(['train', 'val'], loc='upper left')

score = model.evaluate(X_test, y_test, verbose=0)
print("Test loss:", score[0])

